{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "local_setup_instructions_v3",
   "metadata": {},
   "source": [
    "# Voice Extractor UI - Advanced Local Setup & Usage\n",
    "\n",
    "This notebook provides an enhanced graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, optimized for local Python environments (e.g., Jupyter Notebook/Lab).\n",
    "\n",
    "## Local Setup Instructions (Crucial)\n",
    "\n",
    "1.  **Clone Voice_Extractor Repository:**\n",
    "    *   Ensure Git is installed.\n",
    "    *   Clone the repository:\n",
    "        ```bash\n",
    "        git clone https://github.com/ReisCook/Voice_Extractor.git\n",
    "        ```\n",
    "    *   **Location:** This UI notebook attempts to find the `Voice_Extractor` directory relative to itself (e.g., in the same folder or one level up). If it cannot be found automatically, the UI will provide a field to specify the path to `Voice_Extractor/run_extractor.py`.\n",
    "\n",
    "2.  **Create & Activate Python Virtual Environment (Strongly Recommended):**\n",
    "    ```bash\n",
    "    python -m venv venv_ve_ui\n",
    "    # On macOS/Linux:\n",
    "    source venv_ve_ui/bin/activate\n",
    "    # On Windows:\n",
    "    .\\venv_ve_ui\\Scripts\\activate\n",
    "    ```\n",
    "\n",
    "3.  **Install Dependencies (within the activated environment):**\n",
    "    *   Install UI-specific dependencies:\n",
    "        ```bash\n",
    "        pip install ipywidgets pandas matplotlib huggingface_hub datasets\n",
    "        ```\n",
    "    *   Install Voice_Extractor's dependencies:\n",
    "        ```bash\n",
    "        pip install -r Voice_Extractor/requirements.txt \n",
    "        ```\n",
    "        *(If `Voice_Extractor` is not in the current directory, adjust the path to `requirements.txt`)*\n",
    "\n",
    "4.  **Accept Hugging Face Model Terms:**\n",
    "    *   Log in to your Hugging Face account in your browser.\n",
    "    *   Visit and accept the terms of use for these models (required for PyAnnote functionality):\n",
    "        - [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "        - [pyannote/overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
    "        - (And implicitly, their dependencies like segmentation models).\n",
    "    *   The Hugging Face Token you provide in the UI must correspond to this account.\n",
    "\n",
    "5.  **Launch Jupyter and Run this Notebook:**\n",
    "    Navigate to the directory containing this notebook and launch Jupyter:\n",
    "    ```bash\n",
    "    jupyter lab  # or jupyter notebook\n",
    "    ```\n",
    "    Open this notebook and run the code cell below to initialize the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ee9d7_advanced_local",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Audio\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "# --- Dependency Check --- \n",
    "missing_deps = []\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except ImportError:\n",
    "    missing_deps.append(\"ipywidgets\")\n",
    "try:\n",
    "    from huggingface_hub import login\n",
    "except ImportError:\n",
    "    missing_deps.append(\"huggingface_hub\")\n",
    "try:\n",
    "    import datasets\n",
    "except ImportError:\n",
    "    missing_deps.append(\"datasets\")\n",
    "\n",
    "if missing_deps:\n",
    "    error_html = \"<p style='color:red; font-weight:bold;'>ERROR: Missing critical Python packages!</p>\"\n",
    "    error_html += \"<p>Please install them by running: <code>pip install \" + ' '.join(missing_deps) + \"</code></p>\"\n",
    "    error_html += \"<p>Also ensure pandas and matplotlib are installed. Refer to the setup instructions above.</p>\"\n",
    "    display(HTML(error_html))\n",
    "    # Prevent further execution if core UI components are missing\n",
    "    if \"ipywidgets\" in missing_deps:\n",
    "        raise ImportError(\"ipywidgets is missing, UI cannot be rendered.\")\n",
    "else:\n",
    "    from ipywidgets import Layout, HBox, VBox, GridBox # Explicit imports for clarity\n",
    "\n",
    "# --- Global Configuration and State ---\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "VOICE_EXTRACTOR_SCRIPT_PATH = None # To be determined or set by user\n",
    "\n",
    "# --- UI Helper Functions ---\n",
    "def create_section(title, level=3):\n",
    "    return widgets.HTML(f\"<h{level}>{title}</h{level}>\")\n",
    "\n",
    "def create_text_input(description, placeholder=\"\", value=\"\", required=False, password=False, width='100%'):\n",
    "    widget_class = widgets.Password if password else widgets.Text\n",
    "    return widget_class(\n",
    "        value=value,\n",
    "        description=f\"{'*' if required else ''}{description}:\",\n",
    "        placeholder=placeholder,\n",
    "        layout=Layout(width=width),\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "def create_path_input_with_status(description, default_value, required=True, check_type='any'):\n",
    "    text_input = create_text_input(description, placeholder=\"Enter path...\", value=default_value, required=required, width='auto')\n",
    "    status_label = widgets.Label(\"\", layout=Layout(width='100px', margin='0 0 0 5px'))\n",
    "    \n",
    "    def _validate_path_on_blur(change):\n",
    "        path_str = change.new.strip()\n",
    "        if not path_str and required:\n",
    "            status_label.value = \"✗ Required\"\n",
    "            status_label.layout.color = 'red'\n",
    "            return\n",
    "        if not path_str and not required:\n",
    "            status_label.value = \"\"\n",
    "            return\n",
    "        \n",
    "        p = Path(path_str).expanduser()\n",
    "        if not p.exists():\n",
    "            status_label.value = \"✗ Not Found\"\n",
    "            status_label.layout.color = 'red'\n",
    "        elif check_type == 'dir' and not p.is_dir():\n",
    "            status_label.value = \"✗ Not a Dir\"\n",
    "            status_label.layout.color = 'red'\n",
    "        elif check_type == 'file' and not p.is_file():\n",
    "            status_label.value = \"✗ Not a File\"\n",
    "            status_label.layout.color = 'red'\n",
    "        else:\n",
    "            status_label.value = \"✓ Valid\"\n",
    "            status_label.layout.color = 'green'\n",
    "        validate_inputs() # Trigger main validation\n",
    "        \n",
    "    text_input.observe(_validate_path_on_blur, names='value') # Validate on value change (includes blur)\n",
    "    # Initial validation for default value\n",
    "    if default_value: _validate_path_on_blur({'new': default_value})\n",
    "        \n",
    "    return HBox([text_input, status_label], layout=Layout(width='100%', align_items='center'))\n",
    "\n",
    "def create_dropdown(description, options, default_value=None, width='100%'):\n",
    "    actual_default = default_value if default_value in options else (options[0] if options else None)\n",
    "    return widgets.Dropdown(\n",
    "        description=f\"{description}:\", options=options, value=actual_default,\n",
    "        layout=Layout(width=width), style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "def create_slider(description, min_val, max_val, step, default, width='100%'):\n",
    "    return widgets.FloatSlider(\n",
    "        description=f\"{description}:\", min=min_val, max=max_val, step=step, value=default,\n",
    "        layout=Layout(width=width), style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "def create_checkbox(description, initial_value=False, width='auto'):\n",
    "    return widgets.Checkbox(\n",
    "        description=description, value=initial_value, indent=False,\n",
    "        layout=Layout(width=width)\n",
    "    )\n",
    "\n",
    "# --- Find Voice_Extractor Script --- \n",
    "ve_script_path_input_container = VBox([]) # Container for conditional input field\n",
    "def find_ve_script():\n",
    "    global VOICE_EXTRACTOR_SCRIPT_PATH\n",
    "    potential_roots = [NOTEBOOK_CWD, NOTEBOOK_CWD.parent]\n",
    "    for root in potential_roots:\n",
    "        script_p = root / 'Voice_Extractor' / 'run_extractor.py'\n",
    "        if script_p.is_file():\n",
    "            VOICE_EXTRACTOR_SCRIPT_PATH = script_p.resolve()\n",
    "            ve_script_path_input_container.children = [\n",
    "                widgets.HTML(f\"<p>Found <code>run_extractor.py</code> at: <code>{VOICE_EXTRACTOR_SCRIPT_PATH}</code></p>\")\n",
    "            ]\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "if not find_ve_script():\n",
    "    ve_script_path_label = widgets.HTML(\"<p style='color:red; font-weight:bold;'><code>Voice_Extractor/run_extractor.py</code> not found automatically.</p> <p>Please provide the full path to <code>run_extractor.py</code> or the root of the Voice_Extractor repository:</p>\")\n",
    "    user_ve_path_input = create_text_input(\"Path to run_extractor.py or Voice_Extractor Repo\", value=\"\", width='70%')\n",
    "    \n",
    "    def _update_ve_script_path(change):\n",
    "        global VOICE_EXTRACTOR_SCRIPT_PATH\n",
    "        p = Path(change.new.strip()).expanduser()\n",
    "        if p.is_file() and p.name == 'run_extractor.py':\n",
    "            VOICE_EXTRACTOR_SCRIPT_PATH = p.resolve()\n",
    "            user_ve_path_input.layout.border = '1px solid green'\n",
    "        elif p.is_dir() and (p / 'run_extractor.py').is_file():\n",
    "            VOICE_EXTRACTOR_SCRIPT_PATH = (p / 'run_extractor.py').resolve()\n",
    "            user_ve_path_input.layout.border = '1px solid green'\n",
    "        else:\n",
    "            VOICE_EXTRACTOR_SCRIPT_PATH = None\n",
    "            user_ve_path_input.layout.border = '1px solid red'\n",
    "        validate_inputs()\n",
    "            \n",
    "    user_ve_path_input.observe(_update_ve_script_path, names='value')\n",
    "    ve_script_path_input_container.children = [ve_script_path_label, user_ve_path_input]\n",
    "\n",
    "# --- UI Element Definitions ---\n",
    "hf_token = create_text_input(\"Hugging Face Token\", placeholder=\"hf_...\", required=True, password=True, width='50%')\n",
    "\n",
    "default_audio_dir = str(NOTEBOOK_CWD / 'sample_audio_files')\n",
    "default_ref_audio = str(Path(default_audio_dir) / 'reference_speaker.wav')\n",
    "default_output_dir_base = str(NOTEBOOK_CWD / 'voice_extractor_runs')\n",
    "\n",
    "audio_dir_box = create_path_input_with_status(\"Audio Directory\", default_audio_dir, check_type='dir')\n",
    "reference_file_box = create_path_input_with_status(\"Reference Audio File\", default_ref_audio, check_type='file')\n",
    "target_name = create_text_input(\"Target Speaker Name\", placeholder=\"e.g., Speaker01\", required=True, width='50%')\n",
    "output_dir_box = create_path_input_with_status(\"Base Output Directory\", default_output_dir_base, check_type='any') # 'any' as it will be created\n",
    "\n",
    "output_sr = create_dropdown(\"Output Sample Rate\", [16000, 22050, 24000, 44100, 48000], 24000, width='auto')\n",
    "whisper_model = create_dropdown(\"Whisper Model\", \n",
    "    ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3'], 'large-v3', width='auto')\n",
    "language = create_text_input(\"Language Code\", placeholder=\"en, es, (empty for auto)\", value=\"en\", width='auto')\n",
    "\n",
    "skip_demucs = create_checkbox(\"Skip Demucs Vocal Separation\", initial_value=True)\n",
    "skip_demucs_desc = widgets.HTML(\"<small>Recommended. Uncheck if source audio has mixed vocals/music and needs separation.</small>\")\n",
    "\n",
    "min_duration = create_slider(\"Min Segment (s)\", 0.5, 10.0, 0.1, 1.0, width='auto')\n",
    "merge_gap = create_slider(\"Merge Gap (s)\", 0.0, 2.0, 0.05, 0.25, width='auto')\n",
    "verification_threshold = create_slider(\"Verify Thresh.\", 0.0, 1.0, 0.01, 0.69, width='auto')\n",
    "concat_silence = create_slider(\"Concat Silence (s)\", 0.0, 5.0, 0.1, 0.5, width='auto')\n",
    "disable_speechbrain = create_checkbox(\"Disable SpeechBrain Verify\")\n",
    "skip_rejected_transcripts = create_checkbox(\"Skip Transcribing Rejected\")\n",
    "diar_model = create_dropdown(\"Diar. Model\", [\"pyannote/speaker-diarization-3.1\", \"pyannote/speaker-diarization-3.0\"], \"pyannote/speaker-diarization-3.1\", width='auto')\n",
    "osd_model = create_dropdown(\"OSD Model\", [\"pyannote/overlapped-speech-detection\"], \"pyannote/overlapped-speech-detection\", width='auto')\n",
    "dry_run = create_checkbox(\"Dry Run (first 60s)\")\n",
    "debug_log = create_checkbox(\"Verbose Debug Log\")\n",
    "keep_temp_files = create_checkbox(\"Keep Temp Files\")\n",
    "\n",
    "output_method = create_dropdown(\"Output Method\", [\"Save ZIP to Local Output Directory\"], \"Save ZIP to Local Output Directory\", width='auto')\n",
    "push_to_hf = create_checkbox(\"Push Dataset to Hugging Face Hub\")\n",
    "hf_dataset_repo = create_text_input(\"HF Dataset Repo\", placeholder=\"username/dataset_name\", width='auto')\n",
    "hf_dataset_private = create_checkbox(\"Make HF Dataset Private\", initial_value=True)\n",
    "hf_dataset_repo.disabled = True\n",
    "hf_dataset_private.disabled = True\n",
    "\n",
    "start_btn = widgets.Button(description=\"🚀 Start Extraction\", button_style='success', icon='play', disabled=True, layout=Layout(width='250px', height='40px'))\n",
    "status_message = widgets.HTML(\"<p style='color:blue;'>Status: Configure and validate inputs.</p>\")\n",
    "validation_message = widgets.HTML(\"\") # For detailed validation errors\n",
    "log_output = widgets.Output(layout=Layout(height='400px', overflow_y='scroll', border='1px solid #ccc', margin='10px 0 0 0'))\n",
    "results_output = widgets.Output(layout=Layout(margin='10px 0 0 0'))\n",
    "\n",
    "# --- Event Handlers & Validation Logic ---\n",
    "def get_path_from_box(box_widget):\n",
    "    return box_widget.children[0].value.strip()\n",
    "\n",
    "def is_path_box_valid(box_widget):\n",
    "    return box_widget.children[1].value == \"✓ Valid\"\n",
    "\n",
    "def validate_inputs(*args):\n",
    "    errors = []\n",
    "    # Check Voice Extractor Script Path\n",
    "    if not VOICE_EXTRACTOR_SCRIPT_PATH or not VOICE_EXTRACTOR_SCRIPT_PATH.is_file():\n",
    "        errors.append(\"Path to <code>Voice_Extractor/run_extractor.py</code> is invalid or not set.\")\n",
    "    \n",
    "    # Required text fields\n",
    "    if not hf_token.value.strip(): errors.append(\"Hugging Face Token is required.\")\n",
    "    if not target_name.value.strip(): errors.append(\"Target Speaker Name is required.\")\n",
    "\n",
    "    # Path inputs from boxes\n",
    "    audio_dir_val = get_path_from_box(audio_dir_box)\n",
    "    ref_file_val = get_path_from_box(reference_file_box)\n",
    "    output_dir_val = get_path_from_box(output_dir_box)\n",
    "\n",
    "    if not audio_dir_val: errors.append(\"Audio Directory path is required.\")\n",
    "    elif not is_path_box_valid(audio_dir_box): errors.append(\"Audio Directory path is invalid (check status). Current: '\" + audio_dir_val + \"'\")\n",
    "    \n",
    "    if not ref_file_val: errors.append(\"Reference Audio File path is required.\")\n",
    "    elif not is_path_box_valid(reference_file_box): errors.append(\"Reference Audio File path is invalid (check status). Current: '\" + ref_file_val + \"'\")\n",
    "\n",
    "    if not output_dir_val: errors.append(\"Base Output Directory path is required.\")\n",
    "    else:\n",
    "        try:\n",
    "            p_out_parent = Path(output_dir_val).expanduser().parent\n",
    "            if not p_out_parent.is_dir() or not os.access(str(p_out_parent), os.W_OK):\n",
    "                 errors.append(f\"Base Output Directory's parent ('{p_out_parent}') is not found or not writable.\")\n",
    "        except Exception as e:\n",
    "            errors.append(f\"Error checking Base Output Directory parent: {e}\")\n",
    "\n",
    "    if push_to_hf.value and not hf_dataset_repo.value.strip():\n",
    "        errors.append(\"HF Dataset Repo is required when 'Push to Hugging Face Hub' is checked.\")\n",
    "\n",
    "    if not errors:\n",
    "        validation_message.value = \"<p style='color:green;'>All inputs valid. Ready to start.</p>\"\n",
    "        start_btn.disabled = False\n",
    "    else:\n",
    "        validation_message.value = \"<p style='color:red; font-weight:bold;'>Please fix the following issues:</p><ul><li>\" + \"</li><li>\".join(errors) + \"</li></ul>\"\n",
    "        start_btn.disabled = True\n",
    "\n",
    "# Observe all relevant input widgets\n",
    "for w_obj in [hf_token, target_name, hf_dataset_repo,\n",
    "             output_sr, whisper_model, language, skip_demucs,\n",
    "             min_duration, merge_gap, verification_threshold, concat_silence,\n",
    "             disable_speechbrain, skip_rejected_transcripts, diar_model, osd_model,\n",
    "             dry_run, debug_log, keep_temp_files, output_method, push_to_hf, hf_dataset_private]:\n",
    "    w_obj.observe(validate_inputs, names='value')\n",
    "# Path boxes trigger validation internally, which then calls validate_inputs\n",
    "\n",
    "def toggle_hf_fields(change):\n",
    "    is_enabled = change.new\n",
    "    hf_dataset_repo.disabled = not is_enabled\n",
    "    hf_dataset_private.disabled = not is_enabled\n",
    "    validate_inputs()\n",
    "push_to_hf.observe(toggle_hf_fields, names='value')\n",
    "\n",
    "# --- Main Execution Function ---\n",
    "def run_extraction(b):\n",
    "    log_output.clear_output()\n",
    "    results_output.clear_output()\n",
    "    start_btn.disabled = True\n",
    "    start_btn.description = \"🔄 Processing...\"\n",
    "    start_btn.icon = \"spinner\"\n",
    "    status_message.value = \"<p style='color:blue;'>Status: Initializing...</p>\"\n",
    "\n",
    "    with log_output:\n",
    "        try:\n",
    "            if not VOICE_EXTRACTOR_SCRIPT_PATH or not VOICE_EXTRACTOR_SCRIPT_PATH.is_file():\n",
    "                raise FileNotFoundError(\"Voice_Extractor script (run_extractor.py) path is not correctly set or file not found.\")\n",
    "\n",
    "            print(f\"Using Voice_Extractor script: {VOICE_EXTRACTOR_SCRIPT_PATH}\")\n",
    "            print(f\"Authenticating with Hugging Face (token: {hf_token.value[:4]}...)\")\n",
    "            login(token=hf_token.value, add_to_git_credential=False)\n",
    "            print(\"✅ Hugging Face Authentication successful.\")\n",
    "\n",
    "            audio_dir_p = Path(get_path_from_box(audio_dir_box)).expanduser().resolve()\n",
    "            ref_file_p = Path(get_path_from_box(reference_file_box)).expanduser().resolve()\n",
    "            target_speaker_name = target_name.value.strip()\n",
    "            base_output_dir_p = Path(get_path_from_box(output_dir_box)).expanduser().resolve()\n",
    "            \n",
    "            # Create a timestamped subdirectory for this specific run\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            run_specific_output_dir = base_output_dir_p / f\"{target_speaker_name.replace(' ', '_')}_{timestamp}\"\n",
    "            run_specific_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Outputs for this run will be saved in: {run_specific_output_dir}\")\n",
    "\n",
    "            audio_files_in_dir = []\n",
    "            for ext in ['.wav', '.mp3', '.m4a', '.flac']:\n",
    "                audio_files_in_dir.extend(list(audio_dir_p.rglob(f\"*{ext}\")))\n",
    "            if not audio_files_in_dir:\n",
    "                raise FileNotFoundError(f\"No compatible audio files found in {audio_dir_p}\")\n",
    "            input_audio_file_p = audio_files_in_dir[0]\n",
    "            print(f\"Processing audio file: {input_audio_file_p}\")\n",
    "\n",
    "            cmd_list = [\n",
    "                \"python\", str(VOICE_EXTRACTOR_SCRIPT_PATH),\n",
    "                \"--input-audio\", str(input_audio_file_p),\n",
    "                \"--reference-audio\", str(ref_file_p),\n",
    "                \"--target-name\", target_speaker_name,\n",
    "                \"--output-base-dir\", str(run_specific_output_dir), # Use run-specific dir for script output\n",
    "                \"--token\", hf_token.value,\n",
    "                \"--output-sr\", str(output_sr.value),\n",
    "                \"--whisper-model\", whisper_model.value,\n",
    "                \"--min-duration\", str(min_duration.value),\n",
    "                \"--merge-gap\", str(merge_gap.value),\n",
    "                \"--verification-threshold\", str(verification_threshold.value),\n",
    "                \"--concat-silence\", str(concat_silence.value),\n",
    "                \"--diar-model\", diar_model.value,\n",
    "                \"--osd-model\", osd_model.value\n",
    "            ]\n",
    "            if language.value.strip(): cmd_list.extend([\"--language\", language.value.strip()])\n",
    "            if skip_demucs.value: cmd_list.append(\"--skip-demucs\")\n",
    "            if disable_speechbrain.value: cmd_list.append(\"--disable-speechbrain\")\n",
    "            if skip_rejected_transcripts.value: cmd_list.append(\"--skip-rejected-transcripts\")\n",
    "            if dry_run.value: cmd_list.append(\"--dry-run\")\n",
    "            if debug_log.value: cmd_list.append(\"--debug\")\n",
    "            if keep_temp_files.value: cmd_list.append(\"--keep-temp-files\")\n",
    "\n",
    "            status_message.value = \"<p style='color:blue;'>Status: Running Voice Extractor script...</p>\"\n",
    "            print(f\"Executing command: {' '.join(cmd_list)}\\n--- SCRIPT LOG START ---\")\n",
    "            process = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                                     text=True, bufsize=1, universal_newlines=True, shell=False)\n",
    "            full_log_output = []\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "                full_log_output.append(line)\n",
    "            exit_code = process.wait()\n",
    "            full_log_str = \"\".join(full_log_output)\n",
    "            print(\"--- SCRIPT LOG END ---\")\n",
    "\n",
    "            if exit_code == 0:\n",
    "                status_message.value = \"<p style='color:green;'>Status: Voice extraction completed successfully!</p>\"\n",
    "                # The script saves its outputs inside a subfolder of `run_specific_output_dir` named like\n",
    "                # f\"{target_speaker_name.replace(' ', '_')}_{input_audio_file_p.stem}_SOLO_Split\"\n",
    "                # This is the `actual_script_output_sub_dir`\n",
    "                actual_script_output_sub_dir_name = f\"{target_speaker_name.replace(' ', '_')}_{input_audio_file_p.stem}_SOLO_Split\"\n",
    "                actual_script_output_sub_dir = run_specific_output_dir / actual_script_output_sub_dir_name\n",
    "\n",
    "                if not actual_script_output_sub_dir.is_dir():\n",
    "                    print(f\"\\n⚠️ Warning: Expected script output sub-directory {actual_script_output_sub_dir} not found. ZIP and HF push might fail or be incorrect.\")\n",
    "                else:\n",
    "                    print(f\"\\nScript outputs generated in: {actual_script_output_sub_dir}\")\n",
    "\n",
    "                if output_method.value == \"Save ZIP to Local Output Directory\" and actual_script_output_sub_dir.is_dir():\n",
    "                    zip_base_name = run_specific_output_dir / f\"{target_speaker_name.replace(' ', '_')}_{input_audio_file_p.stem}_dataset_{timestamp}\" # zip in run_specific_output_dir\n",
    "                    zip_file_path = shutil.make_archive(str(zip_base_name), 'zip', root_dir=actual_script_output_sub_dir.parent, base_dir=actual_script_output_sub_dir.name)\n",
    "                    print(f\"\\n✅ ZIP archive created: {Path(zip_file_path).resolve()}\")\n",
    "                \n",
    "                if push_to_hf.value and actual_script_output_sub_dir.is_dir():\n",
    "                    print(f\"\\nPreparing to push dataset to Hugging Face: {hf_dataset_repo.value.strip()}\")\n",
    "                    from datasets import load_dataset, Audio as HFAudio # Local import\n",
    "                    verified_csv_files = list(actual_script_output_sub_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                    if not verified_csv_files:\n",
    "                        print(f\"❌ Error: No verified transcript CSV found in {actual_script_output_sub_dir / 'transcripts_solo_verified'}. Cannot push.\")\n",
    "                    else:\n",
    "                        try:\n",
    "                            ds = load_dataset('csv', data_files={'train': str(verified_csv_files[0])}, data_dir=str(actual_script_output_sub_dir))\n",
    "                            if 'filename' not in ds['train'].column_names: raise ValueError(\"CSV 'filename' column missing.\")\n",
    "                            ds = ds.cast_column('filename', HFAudio(sampling_rate=int(output_sr.value)))\n",
    "                            ds.push_to_hub(hf_dataset_repo.value.strip(), private=hf_dataset_private.value, token=hf_token.value, embed_external_files=True)\n",
    "                            print(f\"✅ Dataset pushed to https://huggingface.co/datasets/{hf_dataset_repo.value.strip()}\")\n",
    "                        except Exception as hf_err:\n",
    "                            print(f\"❌ HF Push Error: {hf_err}\")\n",
    "                            traceback.print_exc()\n",
    "\n",
    "                # Display results from actual_script_output_sub_dir\n",
    "                with results_output:\n",
    "                    display(create_section(\"Extraction Results Summary\", level=2))\n",
    "                    if actual_script_output_sub_dir.is_dir():\n",
    "                        concat_audio = list(actual_script_output_sub_dir.glob(\"concatenated_audio_solo/*.wav\"))\n",
    "                        if concat_audio: display(HTML(f\"<b>Concatenated Audio:</b> {concat_audio[0].name}\")); display(Audio(str(concat_audio[0])))\n",
    "                        transcript_csv = list(actual_script_output_sub_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                        if transcript_csv: \n",
    "                            df = pd.read_csv(transcript_csv[0])\n",
    "                            display(HTML(f\"<b>Transcript Sample (from {transcript_csv[0].name}):</b>\")); display(df.head())\n",
    "                            display(HTML(f\"<p>Total Segments: {len(df)}</p>\"))\n",
    "                    else:\n",
    "                        display(HTML(\"<p style='color:orange;'>Could not find script output sub-directory to display results.</p>\"))\n",
    "            else:\n",
    "                if \"Demucs failed! (RC: -9)\" in full_log_str:\n",
    "                    status_message.value = \"<p style='color:red;'><b>Error: Demucs ran out of memory.</b> Try with 'Skip Demucs' or use a smaller file/more powerful machine.</p>\"\n",
    "                else:\n",
    "                    status_message.value = f\"<p style='color:red;'><b>Error: Voice extraction failed (exit code {exit_code}).</b> Check Processing Log.</p>\"\n",
    "                print(f\"\\n❌ Process failed with exit code: {exit_code}\")\n",
    "\n",
    "        except FileNotFoundError as fnf_err:\n",
    "            status_message.value = f\"<p style='color:red;'><b>File Not Found Error:</b> {fnf_err}</p>\"\n",
    "            print(f\"❌ FileNotFoundError: {fnf_err}\")\n",
    "        except Exception as e_gen:\n",
    "            status_message.value = f\"<p style='color:red;'><b>An unexpected error occurred:</b> {e_gen}</p>\"\n",
    "            print(f\"❌ Unexpected Error: {e_gen}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            start_btn.disabled = False\n",
    "            start_btn.description = \"🚀 Start Extraction\"\n",
    "            start_btn.icon = \"play\"\n",
    "            validate_inputs() # Re-check validation state\n",
    "\n",
    "start_btn.on_click(run_extraction)\n",
    "\n",
    "# --- UI Layout Construction ---\n",
    "config_box = VBox([\n",
    "    create_section(\"Core Configuration\", level=2),\n",
    "    ve_script_path_input_container, # For user to specify VE script path if not found\n",
    "    hf_token\n",
    "], layout=Layout(border='1px solid #ddd', padding='10px', margin_bottom='15px'))\n",
    "\n",
    "inputs_box = VBox([\n",
    "    create_section(\"Input Parameters\", level=2),\n",
    "    audio_dir_box,\n",
    "    reference_file_box,\n",
    "    target_name,\n",
    "    output_dir_box\n",
    "], layout=Layout(border='1px solid #ddd', padding='10px', margin_bottom='15px'))\n",
    "\n",
    "processing_opts_box = VBox([\n",
    "    create_section(\"Processing Options\", level=2),\n",
    "    GridBox([output_sr, whisper_model, language], layout=Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='10px')),\n",
    "    HBox([skip_demucs, skip_demucs_desc], layout=Layout(margin_top='10px', align_items='center')),\n",
    "    memory_warning\n",
    "], layout=Layout(border='1px solid #ddd', padding='10px', margin_bottom='15px'))\n",
    "\n",
    "adv_segment_params = VBox([min_duration, merge_gap, verification_threshold, concat_silence])\n",
    "adv_verify_transcribe = VBox([disable_speechbrain, skip_rejected_transcripts])\n",
    "adv_models = VBox([diar_model, osd_model])\n",
    "adv_debug = VBox([dry_run, debug_log, keep_temp_files])\n",
    "\n",
    "advanced_accordion = widgets.Accordion(\n",
    "    children=[adv_segment_params, adv_verify_transcribe, adv_models, adv_debug],\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "advanced_accordion.set_title(0, 'Segment & Merging')\n",
    "advanced_accordion.set_title(1, 'Verification & Transcription')\n",
    "advanced_accordion.set_title(2, 'Specialized Models')\n",
    "advanced_accordion.set_title(3, 'Debug & Temporary Files')\n",
    "\n",
    "advanced_box = VBox([\n",
    "    create_section(\"Advanced Settings\", level=2),\n",
    "    advanced_accordion\n",
    "], layout=Layout(border='1px solid #ddd', padding='10px', margin_bottom='15px'))\n",
    "\n",
    "output_export_box = VBox([\n",
    "    create_section(\"Output & Export\", level=2),\n",
    "    output_method,\n",
    "    HBox([push_to_hf, hf_dataset_private], layout=Layout(margin_top='5px')),\n",
    "    hf_dataset_repo\n",
    "], layout=Layout(border='1px solid #ddd', padding='10px', margin_bottom='15px'))\n",
    "\n",
    "run_control_box = VBox([\n",
    "    HBox([start_btn, validation_message], layout=Layout(align_items='center')),\n",
    "    status_message\n",
    "], layout=Layout(margin_top='20px'))\n",
    "\n",
    "main_ui_layout = VBox([\n",
    "    create_section(\"Voice Extractor - Local UI\", level=1),\n",
    "    config_box,\n",
    "    inputs_box,\n",
    "    processing_opts_box,\n",
    "    advanced_box,\n",
    "    output_export_box,\n",
    "    run_control_box,\n",
    "    create_section(\"Processing Log\", level=2),\n",
    "    log_output,\n",
    "    create_section(\"Results Summary\", level=2),\n",
    "    results_output\n",
    "])\n",
    "\n",
    "# Initial validation call\n",
    "validate_inputs()\n",
    "display(main_ui_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8137fb8_original_local",
   "metadata": {},
   "source": [
    "# Voice Extractor - Usage Instructions\n",
    "\n",
    "This notebook provides a graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, which identifies, isolates, and transcribes clean solo segments of a target speaker from multi-speaker audio recordings.\n",
    "\n",
    "## How to Use (After Local Setup from Above)\n",
    "\n",
    "1. **Authentication**: Enter your HuggingFace User Access Token. This is required to access PyAnnote models.\n",
    "2. **Input Files (Local Paths)**:\n",
    "   - Specify the local folder containing your audio (the first compatible audio file found will be processed).\n",
    "   - Select a clean reference audio file (local path) of ONLY your target speaker (5-30 seconds).\n",
    "   - Enter a name for your target speaker.\n",
    "   - Choose a local output directory for results. A sub-directory for each run will be created here.\n",
    "3. **Processing Options**: Configure sample rate, transcription model, and other settings.\n",
    "4. **Advanced Options**: Fine-tune segment parameters, model selection, and debug settings via the accordion.\n",
    "5. **Output Handling**: \n",
    "   - \"Save ZIP to Local Output Directory\" will create a ZIP archive of the run's results.\n",
    "   - Optionally, push the final dataset to the Hugging Face Hub (ensure your HF token has `write` permissions).\n",
    "6. **Start Processing**: Click the \"Start Extraction\" button when all required fields are validated and filled (the button will enable).\n",
    "\n",
    "## Important Notes (Local Version)\n",
    "\n",
    "- You need to accept the terms of use for the PyAnnote models on Hugging Face as detailed in the setup instructions.\n",
    "- You'll need a Hugging Face access token. Create one at: [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n",
    "- For optimal results, provide a clean reference audio with only the target speaker's voice.\n",
    "- The \"Dry Run\" option in Advanced Settings is helpful for testing as it processes only the first 60 seconds.\n",
    "- GPU acceleration will be used if available and your environment (PyTorch, CUDA) is correctly configured. This significantly speeds up processing.\n",
    "- **Need Help with Voice_Extractor?** If you encounter issues with the underlying script or have questions about its parameters, feel free to contact Reis Cook (reiscook@gmail.com) or check the original repository.\n",
    "\n",
    "For more detailed documentation on the core tool, visit the [Voice Extractor GitHub repository](https://github.com/ReisCook/Voice_Extractor).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
